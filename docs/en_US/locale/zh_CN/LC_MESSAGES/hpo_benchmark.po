# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, Microsoft
# This file is distributed under the same license as the NNI package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: NNI \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-29 17:40+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../hpo_benchmark.rst:4
msgid "HPO Benchmark Example Statistics"
msgstr ""

#: ../../hpo_benchmark.rst:2
msgid "HPO Benchmarks"
msgstr ""

#: ../../hpo_benchmark.rst:9
msgid ""
"We provide a benchmarking tool to compare the performances of tuners "
"provided by NNI (and users' custom tuners) on different types of tasks. "
"This tool uses the `automlbenchmark repository "
"<https://github.com/openml/automlbenchmark)>`_  to run different "
"*benchmarks* on the NNI *tuners*. The tool is located in "
"``examples/trials/benchmarking/automlbenchmark``. This document provides "
"a brief introduction to the tool, its usage, and currently available "
"benchmarks."
msgstr ""

#: ../../hpo_benchmark.rst:14
msgid "Overview and Terminologies"
msgstr ""

#: ../../hpo_benchmark.rst:16
msgid ""
"Ideally, an **HPO Benchmark** provides a tuner with a search space, calls"
" the tuner repeatedly, and evaluates how the tuner probes the search "
"space and approaches to good solutions. In addition, inside the "
"benchmark, an evaluator should be associated to each search space for "
"evaluating the score of points in this search space to give feedbacks to "
"the tuner. For instance, the search space could be the space of "
"hyperparameters for a neural network. Then the evaluator should contain "
"train data, test data, and a criterion. To evaluate a point in the search"
" space, the evaluator will train the network on the train data and report"
" the score of the model on the test data as the score for the point."
msgstr ""

#: ../../hpo_benchmark.rst:23
msgid ""
"However, a **benchmark** provided by the automlbenchmark repository only "
"provides part of the functionality of the evaluator. More concretely, it "
"assumes that it is evaluating a **framework**. Different from a tuner, "
"given train data, a **framework** can directly solve a **task** and "
"predict on the test set. The **benchmark** from the automlbenchmark "
"repository directly provides train and test datasets to a **framework**, "
"evaluates the prediction on the test set, and reports this score as the "
"final score. Therefore, to implement **HPO Benchmark** using "
"automlbenchmark, we pair up a tuner with a search space to form a "
"**framework**, and handle the repeated trial-evaluate-feedback loop in "
"the **framework** abstraction. In other words, each **HPO Benchmark** "
"contains two main components: a **benchmark** from the automlbenchmark "
"library, and an **architecture** which defines the search space and the "
"evaluator. To further clarify, we provide the definition for the "
"terminologies used in this document."
msgstr ""

#: ../../hpo_benchmark.rst:32
msgid ""
"**tuner**\\ : a `tuner or advisor provided by NNI "
"<https://nni.readthedocs.io/en/stable/builtin_tuner.html>`_, or a custom "
"tuner provided by the user."
msgstr ""

#: ../../hpo_benchmark.rst:33
msgid ""
"**task**\\ : an abstraction used by automlbenchmark. A task can be "
"thought of as a tuple (dataset, metric). It provides train and test "
"datasets to the frameworks. Then, based on the returns predictions on the"
" test set, the task evaluates the metric (e.g., mse for regression, f1 "
"for classification) and reports the score."
msgstr ""

#: ../../hpo_benchmark.rst:34
msgid ""
"**benchmark**\\ : an abstraction used by automlbenchmark. A benchmark is "
"a set of tasks, along with other external constraints such as time "
"limits."
msgstr ""

#: ../../hpo_benchmark.rst:35
msgid ""
"**framework**\\ : an abstraction used by automlbenchmark. Given a task, a"
" framework solves the proposed regression or classification problem using"
" train data and produces predictions on the test set. In our "
"implementation, each framework is an architecture, which defines a search"
" space. To evaluate a task given by the benchmark on a specific tuner, we"
" let the tuner continuously tune the hyperparameters (by giving it cross-"
"validation score on the train data as feedback) until the time or trial "
"limit is reached. Then, the architecture is retrained on the entire train"
" set using the best set of hyperparameters."
msgstr ""

#: ../../hpo_benchmark.rst:36
msgid ""
"**architecture**\\ : an architecture is a specific method for solving the"
" tasks, along with a set of hyperparameters to optimize (i.e., the search"
" space). See ``./nni/extensions/NNI/architectures`` for examples."
msgstr ""

#: ../../hpo_benchmark.rst:39
msgid "Supported HPO Benchmarks"
msgstr ""

#: ../../hpo_benchmark.rst:41
msgid ""
"From the previous discussion, we can see that to define an **HPO "
"Benchmark**, we need to specify a **benchmark** and an **architecture**."
msgstr ""

#: ../../hpo_benchmark.rst:43
msgid ""
"Currently, the only architectures we support are random forest and MLP. "
"We use the `scikit-learn implementation <https://scikit-"
"learn.org/stable/modules/classes.html#>`_. Typically, there are a number "
"of hyperparameters that may directly affect the performances of random "
"forest and MLP models. We design the search spaces to be the following."
msgstr ""

#: ../../hpo_benchmark.rst:48
msgid "Search Space for Random Forest:"
msgstr ""

#: ../../hpo_benchmark.rst:60
msgid "Search Space for MLP:"
msgstr ""

#: ../../hpo_benchmark.rst:74
msgid ""
"In addition, we write the search space in different ways (e.g., using "
"\"choice\" or \"randint\" or \"loguniform\"). The architecture "
"implementation and search space definition can be found in "
"``./nni/extensions/NNI/architectures/``. You may replace the search space"
" definition in this file to experiment different search spaces."
msgstr ""

#: ../../hpo_benchmark.rst:78
msgid ""
"For the automlbenchmarks, in addition to the built-in benchmarks provided"
" by automl (defined in "
"``/examples/trials/benchmarking/automlbenchmark/automlbenchmark/resources/benchmarks/``),"
" we design several additional benchmarks, defined in "
"``/examples/trials/benchmarking/automlbenchmark/nni/benchmarks``. One "
"example of larger benchmarks is \"nnismall\", which consists of 8 "
"regression tasks, 8 binary classification tasks, and 8 multi-class "
"classification tasks. We also provide three separate 8-task benchmarks "
"\"nnismall-regression\", \"nnismall-binary\", and \"nnismall-multiclass\""
" corresponding to the three types of tasks in nnismall. These tasks are "
"suitable to solve with random forest and MLP."
msgstr ""

#: ../../hpo_benchmark.rst:85
msgid ""
"The following table summarizes the benchmarks we provide. For "
"``nnismall``, please check "
"``/examples/trials/benchmarking/automlbenchmark/automlbenchmark/resources/benchmarks/``"
" for a more detailed description for each task. Also, since all tasks are"
" from the OpenML platform, you can find the descriptions of all datasets "
"at `this webpage <https://www.openml.org/search?type=data>`_."
msgstr ""

#: ../../hpo_benchmark.rst:93
msgid "Benchmark name"
msgstr ""

#: ../../hpo_benchmark.rst:94
msgid "Description"
msgstr ""

#: ../../hpo_benchmark.rst:95
msgid "Task List"
msgstr ""

#: ../../hpo_benchmark.rst:96
msgid "Location"
msgstr ""

#: ../../hpo_benchmark.rst:97
msgid "nnivalid"
msgstr ""

#: ../../hpo_benchmark.rst:98
msgid "A three-task benchmark to validate benchmark installation."
msgstr ""

#: ../../hpo_benchmark.rst:99
msgid "``kc2, iris, cholesterol``"
msgstr ""

#: ../../hpo_benchmark.rst:100 ../../hpo_benchmark.rst:104
#: ../../hpo_benchmark.rst:108 ../../hpo_benchmark.rst:112
#: ../../hpo_benchmark.rst:116
msgid "``/examples/trials/benchmarking/automlbenchmark/nni/benchmarks/``"
msgstr ""

#: ../../hpo_benchmark.rst:101
msgid "nnismall-regression"
msgstr ""

#: ../../hpo_benchmark.rst:102
msgid "An eight-task benchmark consisting of **regression** tasks only."
msgstr ""

#: ../../hpo_benchmark.rst:103
msgid ""
"``cholesterol, liver-disorders, kin8nm, cpu_small, titanic_2, boston, "
"stock, space_ga``"
msgstr ""

#: ../../hpo_benchmark.rst:105
msgid "nnismall-binary"
msgstr ""

#: ../../hpo_benchmark.rst:106
msgid ""
"An eight-task benchmark consisting of **binary classification** tasks "
"only."
msgstr ""

#: ../../hpo_benchmark.rst:107
msgid ""
"``Australian, blood-transfusion, christine, credit-g, kc1, kr-vs-kp, "
"phoneme, sylvine``"
msgstr ""

#: ../../hpo_benchmark.rst:109
msgid "nnismall-multiclass"
msgstr ""

#: ../../hpo_benchmark.rst:110
msgid ""
"An eight-task benchmark consisting of **multi-class classification** "
"tasks only."
msgstr ""

#: ../../hpo_benchmark.rst:111
msgid "``car, cnae-9, dilbert, fabert, jasmine, mfeat-factors, segment, vehicle``"
msgstr ""

#: ../../hpo_benchmark.rst:113
msgid "nnismall"
msgstr ""

#: ../../hpo_benchmark.rst:114
msgid ""
"A 24-task benchmark that is the superset of nnismall-regression, "
"nnismall-binary, and nnismall-multiclass."
msgstr ""

#: ../../hpo_benchmark.rst:115
msgid ""
"``cholesterol, liver-disorders, kin8nm, cpu_small, titanic_2, boston, "
"stock, space_ga, Australian, blood-transfusion, christine, credit-g, kc1,"
" kr-vs-kp, phoneme, sylvine, car, cnae-9, dilbert, fabert, jasmine, "
"mfeat-factors, segment, vehicle``"
msgstr ""

#: ../../hpo_benchmark.rst:119
msgid "Setup"
msgstr ""

#: ../../hpo_benchmark.rst:121
msgid ""
"Due to some incompatibilities between automlbenchmark and python 3.8, "
"python 3.7 is recommended for running experiments contained in this "
"folder. First, run the following shell script to clone the "
"automlbenchmark repository. Note: it is recommended to perform the "
"following steps in a separate virtual environment, as the setup code may "
"install several packages."
msgstr ""

#: ../../hpo_benchmark.rst:128
msgid "Run predefined benchmarks on existing tuners"
msgstr ""

#: ../../hpo_benchmark.rst:134
msgid ""
"This script runs the benchmark 'nnivalid', which consists of a regression"
" task, a binary classification task, and a multi-class classification "
"task. After the script finishes, you can find a summary of the results in"
" the folder results_[time]/reports/. To run on other predefined "
"benchmarks, change the ``benchmark`` variable in ``runbenchmark_nni.sh``."
" To change to another search space (by using another architecture), chang"
" the `arch_type` parameter in ``./nni/frameworks.yaml``. Note that "
"currently, we only support ``random_forest`` or ``mlp`` as the "
"`arch_type`. To experiment on other search spaces with the same "
"architecture, please change the search space defined in "
"``./nni/extensions/NNI/architectures/run_[architecture].py``."
msgstr ""

#: ../../hpo_benchmark.rst:141
msgid ""
"The ``./nni/frameworks.yaml`` is the actual configuration file for the "
"HPO Benchmark. The ``limit_type`` parameter specifies the limits for "
"running the benchmark on one tuner. If ``limit_type`` is set to "
"`ntrials`, then the tuner is called for `trial_limit` times and then "
"stopped. If ``limit_type`` is set to `time`, then the tuner is "
"continuously called until timeout for the benchmark is reached. The "
"timeout for the benchmarks can be changed in the each benchmark file "
"located in ``./nni/benchmarks``."
msgstr ""

#: ../../hpo_benchmark.rst:147
msgid ""
"By default, the script runs the benchmark on all embedded tuners in NNI. "
"If provided a list of tuners in [tuner-names], it only runs the tuners in"
" the list. Currently, the following tuner names are supported: \"TPE\", "
"\"Random\", \"Anneal\", \"Evolution\", \"SMAC\", \"GPTuner\", "
"\"MetisTuner\", \"DNGOTuner\", \"Hyperband\", \"BOHB\". It is also "
"possible to run the benchmark on custom tuners. See the next sections for"
" details."
msgstr ""

#: ../../hpo_benchmark.rst:152
msgid ""
"By default, the script runs the specified tuners against the specified "
"benchmark one by one. To run the experiment for all tuners simultaneously"
" in the background, set the \"serialize\" flag to false in "
"``runbenchmark_nni.sh``."
msgstr ""

#: ../../hpo_benchmark.rst:155
msgid ""
"Note: the SMAC tuner, DNGO tuner, and the BOHB advisor has to be manually"
" installed before running benchmarks on them. Please refer to `this page "
"<https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html?highlight=nni>`_"
" for more details on installation."
msgstr ""

#: ../../hpo_benchmark.rst:160
msgid "Run customized benchmarks on existing tuners"
msgstr ""

#: ../../hpo_benchmark.rst:162
msgid ""
"You can design your own benchmarks and evaluate the performance of NNI "
"tuners on them. To run customized benchmarks, add a benchmark_name.yaml "
"file in the folder ``./nni/benchmarks``, and change the ``benchmark`` "
"variable in ``runbenchmark_nni.sh``. See "
"``./automlbenchmark/resources/benchmarks/`` for some examples of defining"
" a custom benchmark."
msgstr ""

#: ../../hpo_benchmark.rst:167
msgid "Run benchmarks on custom tuners"
msgstr ""

#: ../../hpo_benchmark.rst:169
msgid ""
"You may also use the benchmark to compare a custom tuner written by "
"yourself with the NNI built-in tuners. To use custom tuners, first make "
"sure that the tuner inherits from ``nni.tuner.Tuner`` and correctly "
"implements the required APIs. For more information on implementing a "
"custom tuner, please refer to `here "
"<https://nni.readthedocs.io/en/stable/Tuner/CustomizeTuner.html>`_. Next,"
" perform the following steps:"
msgstr ""

#: ../../hpo_benchmark.rst:174
msgid ""
"Install the custom tuner via the command ``nnictl algo register``. Check "
"`this document "
"<https://nni.readthedocs.io/en/stable/Tutorial/Nnictl.html>`_ for "
"details."
msgstr ""

#: ../../hpo_benchmark.rst:175
msgid ""
"In ``./nni/frameworks.yaml``\\ , add a new framework extending the base "
"framework NNI. Make sure that the parameter ``tuner_type`` corresponds to"
" the \"builtinName\" of tuner installed in step 1."
msgstr ""

#: ../../hpo_benchmark.rst:176
msgid "Run the following command"
msgstr ""

#: ../../hpo_benchmark.rst:182
msgid ""
"The benchmark will automatically find and match the tuner newly added to "
"your NNI installation."
msgstr ""

