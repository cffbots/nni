# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, Microsoft
# This file is distributed under the same license as the NNI package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: NNI \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-29 17:43+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../autotune_ref.rst:2
msgid "Python API Reference of Auto Tune"
msgstr ""

#: ../../autotune_ref.rst:4
msgid "Contents"
msgstr ""

#: ../../autotune_ref.rst:7
msgid "Trial"
msgstr ""

#: nni.trial.get_next_parameter:1 of
msgid ""
"Get the hyper paremeters generated by tuner. For a multiphase experiment,"
" it returns a new group of hyper parameters at each call of "
"get_next_parameter. For a non-multiphase (multiPhase is not configured or"
" set to False) experiment, it returns hyper parameters only on the first "
"call for each trial job, it returns None since second call. This API "
"should be called only once in each trial job of an experiment which is "
"not specified as multiphase."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.generate_parameters
#: nni.algorithms.hpo.batch_tuner.BatchTuner.is_valid
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_multiple_parameters
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_parameters
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.generate_parameters
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.add_model
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_best_model
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters
#: nni.assessor.Assessor.assess_trial nni.common.serializer.dump
#: nni.common.serializer.load nni.trial.get_experiment_id
#: nni.trial.get_next_parameter nni.trial.get_sequence_id
#: nni.trial.get_trial_id nni.tuner.Tuner.generate_multiple_parameters
#: nni.tuner.Tuner.generate_parameters nni.utils.merge_parameter of
msgid "Returns"
msgstr ""

#: nni.trial.get_next_parameter:6 of
msgid ""
"A dict object contains the hyper parameters generated by tuner, the keys "
"of the dict are defined in search space. Returns None if no more hyper "
"parameters can be generated by tuner."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.generate_parameters
#: nni.algorithms.hpo.batch_tuner.BatchTuner.is_valid
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_multiple_parameters
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_parameters
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.generate_parameters
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.add_model
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_best_model
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters
#: nni.assessor.Assessor.assess_trial nni.common.serializer.dump
#: nni.common.serializer.load nni.trial.get_experiment_id
#: nni.trial.get_next_parameter nni.trial.get_sequence_id
#: nni.trial.get_trial_id nni.tuner.Tuner.generate_multiple_parameters
#: nni.tuner.Tuner.generate_parameters nni.utils.merge_parameter of
msgid "Return type"
msgstr ""

#: nni.trial.get_current_parameter:1 of
msgid ""
"Get current hyper parameters generated by tuner. It returns the same "
"group of hyper parameters as the last call of get_next_parameter returns."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.generate_parameters
#: nni.algorithms.hpo.batch_tuner.BatchTuner.import_data
#: nni.algorithms.hpo.batch_tuner.BatchTuner.is_valid
#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result
#: nni.algorithms.hpo.batch_tuner.BatchTuner.update_search_space
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_import_data
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_initialize
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_report_metric_data
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_request_trial_jobs
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_trial_end
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_update_search_space
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.trial_end
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_parameters
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.receive_trial_result
#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.update_search_space
#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.update_search_space
#: nni.algorithms.hpo.hyperband_advisor.Hyperband
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_report_metric_data
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_request_trial_jobs
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_trial_end
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.generate_parameters
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.import_data
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.miscs_update_idxs_vals
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.receive_trial_result
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.update_search_space
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.trial_end
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.import_data
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.receive_trial_result
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.update_search_space
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.add_model
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate_parameters
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.receive_trial_result
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.import_data
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.receive_trial_result
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.trial_end
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.update_search_space
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result
#: nni.algorithms.hpo.random_tuner.RandomTuner.update_search_space
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.import_data
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.update_search_space
#: nni.algorithms.hpo.tpe_tuner.TpeTuner
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.trial_end
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.update_search_space
#: nni.assessor.Assessor.assess_trial nni.assessor.Assessor.trial_end
#: nni.common.serializer.dump nni.common.serializer.load
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_report_metric_data
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_request_trial_jobs
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_trial_end
#: nni.trial.get_current_parameter nni.trial.report_final_result
#: nni.trial.report_intermediate_result
#: nni.tuner.Tuner.generate_multiple_parameters
#: nni.tuner.Tuner.generate_parameters nni.tuner.Tuner.receive_trial_result
#: nni.tuner.Tuner.trial_end nni.tuner.Tuner.update_search_space
#: nni.utils.merge_parameter of
msgid "Parameters"
msgstr ""

#: nni.trial.get_current_parameter:4 of
msgid "hyper parameter key"
msgstr ""

#: nni.trial.report_intermediate_result:1 of
msgid "Reports intermediate result to NNI."
msgstr ""

#: nni.trial.report_intermediate_result:3 of
msgid "serializable object."
msgstr ""

#: nni.trial.report_final_result:1 of
msgid "Reports final result to NNI."
msgstr ""

#: nni.trial.report_final_result:3 of
msgid ""
"Usually (for built-in tuners to work), it should be a number, or a dict "
"with key \"default\" (a number), and any other extra keys."
msgstr ""

#: nni.trial.get_experiment_id:1 of
msgid "Get experiment ID."
msgstr ""

#: nni.trial.get_experiment_id:3 of
msgid "Identifier of current experiment"
msgstr ""

#: nni.trial.get_trial_id:1 of
msgid ""
"Get trial job ID which is string identifier of a trial job, for example "
"'MoXrp'. In one experiment, each trial job has an unique string ID."
msgstr ""

#: nni.trial.get_trial_id:4 of
msgid "Identifier of current trial job which is calling this API."
msgstr ""

#: nni.trial.get_sequence_id:1 of
msgid ""
"Get trial job sequence nubmer. A sequence number is an integer value "
"assigned to each trial job base on the order they are submitted, "
"incremental starting from 0. In one experiment, both trial job ID and "
"sequence number are unique for each trial job, they are of different data"
" types."
msgstr ""

#: nni.trial.get_sequence_id:5 of
msgid "Sequence number of current trial job which is calling this API."
msgstr ""

#: ../../autotune_ref.rst:18
msgid "Tuner"
msgstr ""

#: nni.tuner.Tuner:1 of
msgid ""
"Tuner is an AutoML algorithm, which generates a new configuration for the"
" next try. A new trial will run with this configuration."
msgstr ""

#: nni.tuner.Tuner:4 of
msgid ""
"This is the abstract base class for all tuners. Tuning algorithms should "
"inherit this class and override :meth:`update_search_space`, "
":meth:`receive_trial_result`, as well as :meth:`generate_parameters` or "
":meth:`generate_multiple_parameters`."
msgstr ""

#: nni.tuner.Tuner:8 of
msgid ""
"After initializing, NNI will first call :meth:`update_search_space` to "
"tell tuner the feasible region, and then call :meth:`generate_parameters`"
" one or more times to request for hyper-parameter configurations."
msgstr ""

#: nni.tuner.Tuner:11 of
msgid ""
"The framework will train several models with given configuration. When "
"one of them is finished, the final accuracy will be reported to "
":meth:`receive_trial_result`. And then another configuration will be "
"reqeusted and trained, util the whole experiment finish."
msgstr ""

#: nni.tuner.Tuner:15 of
msgid ""
"If a tuner want's to know when a trial ends, it can also override "
":meth:`trial_end`."
msgstr ""

#: nni.tuner.Tuner:17 of
msgid ""
"Tuners use *parameter ID* to track trials. In tuner context, there is a "
"one-to-one mapping between parameter ID and trial. When the framework ask"
" tuner to generate hyper-parameters for a new trial, an ID has already "
"been assigned and can be recorded in :meth:`generate_parameters`. Later "
"when the trial ends, the ID will be reported to :meth:`trial_end`, and "
":meth:`receive_trial_result` if it has a final result. Parameter IDs are "
"unique integers."
msgstr ""

#: nni.tuner.Tuner:25 of
msgid ""
"The type/format of search space and hyper-parameters are not limited, as "
"long as they are JSON-serializable and in sync with trial code. For HPO "
"tuners, however, there is a widely shared common interface, which "
"supports ``choice``, ``randint``, ``uniform``, and so on. See "
"``docs/en_US/Tutorial/SearchSpaceSpec.md`` for details of this interface."
msgstr ""

#: nni.tuner.Tuner:31 of
msgid ""
"[WIP] For advanced tuners which take advantage of trials' intermediate "
"results, an ``Advisor`` interface is under development."
msgstr ""

#: nni.tuner.Tuner:34 of
msgid ""
":obj:`Builtin`, "
":class:`~nni.algorithms.hpo.hyperopt_tuner.hyperopt_tuner.HyperoptTuner`,"
" "
":class:`~nni.algorithms.hpo.evolution_tuner.evolution_tuner.EvolutionTuner`,"
" :class:`~nni.algorithms.hpo.smac_tuner.SMACTuner`, "
":class:`~nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner`, "
":class:`~nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner`,"
" :class:`~nni.algorithms.hpo.metis_tuner.mets_tuner.MetisTuner`, "
":class:`~nni.algorithms.hpo.ppo_tuner.PPOTuner`, "
":class:`~nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner`"
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:1 of
msgid "Callback method which provides multiple sets of hyper-parameters."
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:3 of
msgid ""
"This method will get called when the framework is about to launch one or "
"more new trials."
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:5 of
msgid ""
"If user does not override this method, it will invoke "
":meth:`generate_parameters` on each parameter ID."
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:7 of
msgid "See :meth:`generate_parameters` for details."
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:9 of
msgid "User code must override either this method or :meth:`generate_parameters`."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters:3
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters:5
#: nni.tuner.Tuner.generate_multiple_parameters:11 of
msgid ""
"Unique identifiers for each set of requested hyper-parameters. These will"
" later be used in :meth:`receive_trial_result`."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:10
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:13
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:10
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:13
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:10
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:13
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:10
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.trial_end:7
#: nni.tuner.Tuner.generate_multiple_parameters:14
#: nni.tuner.Tuner.generate_parameters:13
#: nni.tuner.Tuner.receive_trial_result:10 nni.tuner.Tuner.trial_end:7 of
msgid "Unstable parameters which should be ignored by normal users."
msgstr ""

#: nni.tuner.Tuner.generate_multiple_parameters:16 of
msgid ""
"List of hyper-parameters. An empty list indicates there are no more "
"trials."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:1
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:1
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:1
#: nni.tuner.Tuner.generate_parameters:1 of
msgid "Abstract method which provides a set of hyper-parameters."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:3
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:3
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:3
#: nni.tuner.Tuner.generate_parameters:3 of
msgid ""
"This method will get called when the framework is about to launch a new "
"trial, if user does not override :meth:`generate_multiple_parameters`."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:6
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:6
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:6
#: nni.tuner.Tuner.generate_parameters:6 of
msgid ""
"The return value of this method will be received by trials via "
":func:`nni.get_next_parameter`. It should fit in the search space, though"
" the framework will not verify this."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:9
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:9
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:9
#: nni.tuner.Tuner.generate_parameters:9 of
msgid ""
"User code must override either this method or "
":meth:`generate_multiple_parameters`."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:11
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters:3
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:11
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters:4
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:11
#: nni.tuner.Tuner.generate_parameters:11 of
msgid ""
"Unique identifier for requested hyper-parameters. This will later be used"
" in :meth:`receive_trial_result`."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:15
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:15
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:15
#: nni.tuner.Tuner.generate_parameters:15 of
msgid ""
"The hyper-parameters, a dict in most cases, but could be any JSON-"
"serializable type when needed."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_import_data
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_initialize
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_report_metric_data
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_report_metric_data
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_report_metric_data
#: nni.tuner.Tuner.generate_parameters of
msgid "Raises"
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.generate_parameters:18
#: nni.algorithms.hpo.random_tuner.RandomTuner.generate_parameters:18
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.generate_parameters:18
#: nni.tuner.Tuner.generate_parameters:18 of
msgid "If the search space is fully explored, tuner can raise this exception."
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.import_data:1
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.import_data:1
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.import_data:1
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.import_data:1
#: nni.assessor.Assessor.load_checkpoint:1
#: nni.assessor.Assessor.save_checkpoint:1 nni.tuner.Tuner.import_data:1
#: nni.tuner.Tuner.load_checkpoint:1 nni.tuner.Tuner.save_checkpoint:1 of
msgid "Internal API under revising, not recommended for end users."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:1
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:1
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:1
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:1
#: nni.tuner.Tuner.receive_trial_result:1 of
msgid ""
"Abstract method invoked when a trial reports its final result. Must "
"override."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:3
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:3
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:3
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:3
#: nni.tuner.Tuner.receive_trial_result:3 of
msgid ""
"This method only listens to results of algorithm-generated hyper-"
"parameters. Currently customized trials added from web UI will not report"
" result to this method."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:6
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:6
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.receive_trial_result:4
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:6
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result:4
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:6
#: nni.tuner.Tuner.receive_trial_result:6 of
msgid ""
"Unique identifier of used hyper-parameters, same with "
":meth:`generate_parameters`."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:8
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:8
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.receive_trial_result:6
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:8
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result:6
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:8
#: nni.tuner.Tuner.receive_trial_result:8 of
msgid "Hyper-parameters generated by :meth:`generate_parameters`."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.receive_trial_result:9
#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.receive_trial_result:9
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.receive_trial_result:8
#: nni.algorithms.hpo.random_tuner.RandomTuner.receive_trial_result:9
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result:8
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.receive_trial_result:9
#: nni.tuner.Tuner.receive_trial_result:9 of
msgid "Result from trial (the return value of :func:`nni.report_final_result`)."
msgstr ""

#: nni.algorithms.hpo.tpe_tuner.TpeTuner.trial_end:1
#: nni.assessor.Assessor.trial_end:1 nni.tuner.Tuner.trial_end:1 of
msgid ""
"Abstract method invoked when a trial is completed or terminated. Do "
"nothing by default."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.trial_end:4
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.trial_end:3
#: nni.tuner.Tuner.trial_end:3 of
msgid "Unique identifier for hyper-parameters used by this trial."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.trial_end:6
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.trial_end:5
#: nni.assessor.Assessor.trial_end:5 nni.tuner.Tuner.trial_end:5 of
msgid "True if the trial successfully completed; False if failed or terminated."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.update_search_space:1
#: nni.algorithms.hpo.random_tuner.RandomTuner.update_search_space:1
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.update_search_space:1
#: nni.tuner.Tuner.update_search_space:1 of
msgid "Abstract method for updating the search space. Must override."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.update_search_space:3
#: nni.algorithms.hpo.random_tuner.RandomTuner.update_search_space:3
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.update_search_space:3
#: nni.tuner.Tuner.update_search_space:3 of
msgid ""
"Tuners are advised to support updating search space at run-time. If a "
"tuner can only set search space once before generating first hyper-"
"parameters, it should explicitly document this behaviour."
msgstr ""

#: nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner.update_search_space:7
#: nni.algorithms.hpo.random_tuner.RandomTuner.update_search_space:7
#: nni.algorithms.hpo.tpe_tuner.TpeTuner.update_search_space:7
#: nni.tuner.Tuner.update_search_space:7 of
msgid "JSON object defined by experiment owner."
msgstr ""

#: nni.algorithms.hpo.tpe_tuner.TpeTuner:1 of
msgid "Whether optimize to minimize or maximize trial result."
msgstr ""

#: nni.algorithms.hpo.tpe_tuner.TpeTuner:3 of
msgid "The random seed."
msgstr ""

#: nni.algorithms.hpo.tpe_tuner.TpeTuner:5 of
msgid ""
"Advanced users can use this to customize TPE tuner. See `TpeArguments` "
"for details."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner:1 of
msgid "HyperoptTuner is a tuner which using hyperopt algorithm."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.generate_parameters:1 of
msgid "Returns a set of trial (hyper-)parameters, as a serializable object."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.generate_parameters:6 of
msgid "**params**"
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion:1 of
msgid "get suggestion from hyperopt"
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion:3 of
msgid "flag to indicate random search or not (default: {False})"
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.get_suggestion:6 of
msgid "**total_params** -- parameter suggestion"
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.import_data:1
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_import_data:1
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.import_data:1
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.import_data:1 of
msgid "Import additional data for tuning"
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.import_data:3
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_import_data:3
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.import_data:3 of
msgid ""
"a list of dictionarys, each of which has at least two keys, 'parameter' "
"and 'value'"
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.miscs_update_idxs_vals:1 of
msgid "Unpack the idxs-vals format into the list of dictionaries that is `misc`."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.miscs_update_idxs_vals:4 of
msgid "idxs_map is a dictionary of id->id mappings so that the misc['idxs'] can"
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.receive_trial_result:1 of
msgid "Record an observation of the objective function"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.receive_trial_result:7
#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.receive_trial_result:7 of
msgid ""
"if value is dict, it should have \"default\" key. value is final metrics "
"of the trial."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.update_search_space:1 of
msgid "Update search space definition in tuner by search_space in parameters."
msgstr ""

#: nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner.update_search_space:3 of
msgid "Will called when first setup experiemnt or update search space in WebUI."
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner:1 of
msgid "EvolutionTuner is tuner using navie evolution algorithm."
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_multiple_parameters:1
#: of
msgid ""
"Returns multiple sets of trial (hyper-)parameters, as iterable of "
"serializable objects. :param parameter_id_list: Unique identifiers for "
"each set of requested hyper-parameters. :type parameter_id_list: list of "
"int :param \\*\\*kwargs: Not used"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_multiple_parameters:6
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters:8
#: of
msgid "A list of newly generated configurations"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_parameters:1 of
msgid ""
"This function will returns a dict of trial (hyper-)parameters. If no "
"trial configration for now, self.credit plus 1 to send the config later"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.generate_parameters:7 of
msgid "One newly generated configuration."
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.receive_trial_result:1 of
msgid "Record the result from a trial"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.trial_end:1 of
msgid ""
"To deal with trial failure. If a trial fails, random generate the "
"parameters and add into the population. :param parameter_id: Unique "
"identifier for hyper-parameters used by this trial. :type parameter_id: "
"int :param success: True if the trial successfully completed; False if "
"failed or terminated. :type success: bool :param \\*\\*kwargs: Not used"
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.update_search_space:1 of
msgid "Update search space."
msgstr ""

#: nni.algorithms.hpo.evolution_tuner.EvolutionTuner.update_search_space:3 of
msgid "Search_space contains the information that user pre-defined."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner:1 of
msgid ""
"This is a wrapper of [SMAC](https://github.com/automl/SMAC3) following "
"NNI tuner interface. It only supports ``SMAC`` mode, and does not support"
" the multiple instances of SMAC3 (i.e., the same configuration is run "
"multiple times)."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters:1
#: of
msgid ""
"Generate mutiple instances of hyperparameters. If it is a first request, "
"retrieve the instances from initial challengers. While if it is not, "
"request new challengers and retrieve instances from the requested "
"challengers."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters:6
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters:6
#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.trial_end:8
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters:8
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters:6 of
msgid "Not used"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_multiple_parameters:10
#: of
msgid "a list of newly generated configurations"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters:1 of
msgid ""
"Generate one instance of hyperparameters (i.e., one configuration). Get "
"one from SMAC3's ``challengers``."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters:8
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.generate_parameters:8 of
msgid "One newly generated configuration"
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.import_data:1
#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.import_data:1 of
msgid "Import additional data for tuning."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.import_data:3 of
msgid "Each of which has at least two keys, ``parameter`` and ``value``."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess:4 of
msgid "Postprocessing for a set of hyperparameters includes:"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess:2 of
msgid "Convert the values of type ``loguniform`` back to their initial range."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess:3 of
msgid ""
"Convert ``categorical``: categorical values in search space are changed "
"to list of numbers before, those original values will be changed back in "
"this function."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess:6 of
msgid "challenger dict"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.param_postprocess:9 of
msgid "dict which stores copy of challengers"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result:1 of
msgid ""
"Receive a trial's final performance result reported through "
":func:``nni.report_final_result`` by the trial. GridSearchTuner does not "
"need trial's results."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.receive_trial_result:11
#: of
msgid "Received parameter id not in ``self.total_data``"
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.update_search_space:1 of
msgid ""
"Convert search_space to the format that ``SMAC3`` could recognize, thus, "
"not all the search space types are supported. In this function, we also "
"do the initialization of `SMAC3`, i.e., calling ``self._main_cli``."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.update_search_space:4 of
msgid "NOTE: updating search space during experiment running is not supported."
msgstr ""

#: nni.algorithms.hpo.smac_tuner.smac_tuner.SMACTuner.update_search_space:6 of
msgid ""
"The format could be referred to search space spec "
"(https://nni.readthedocs.io/en/latest/Tutorial/SearchSpaceSpec.html)."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:1
#: of
msgid "NetworkMorphismTuner is a tuner which using network morphism techniques."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:5
#: of
msgid "The class number or output node number (default: ``10``)"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner
#: of
msgid "type"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:35
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:43
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:7
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:55
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:61
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:67
#: of
msgid "int"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:11
#: of
msgid "A tuple including: (input_width, input_width, input_channel)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:13
#: of
msgid "tuple"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:17
#: of
msgid ""
"The minimum temperature for simulated annealing. (default: "
"``Constant.T_MIN``)"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:49
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:19
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:25
#: of
msgid "float"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:23
#: of
msgid "The beta in acquisition function. (default: ``Constant.BETA``)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:29
#: of
msgid "algorithm name used in the network morphism (default: ``\"Bayesian\"``)"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:10
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:31
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:37
#: of
msgid "str"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:35
#: of
msgid "optimize mode \"minimize\" or \"maximize\" (default: ``\"minimize\"``)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:41
#: of
msgid "verbose to print the log (default: ``True``)"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:19
#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:28
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:43
#: of
msgid "bool"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:47
#: of
msgid "The optimizer used in networkmorphsim tuner."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:49
#: of
msgid "BayesianOptimizer"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:53
#: of
msgid "max model size to the graph (default: ``Constant.MAX_MODEL_SIZE``)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:59
#: of
msgid "default model length (default: ``Constant.MODEL_LEN``)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:65
#: of
msgid "default model width (default: ``Constant.MODEL_WIDTH``)"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner:73
#: of
msgid "dict"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.add_model:1
#: of
msgid "Add model to the history, x_queue and y_queue"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.add_model:10
#: of
msgid "**model**"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate:1
#: of
msgid "Generate the next neural architecture."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate:3
#: of
msgid ""
"* **other_info** (*any object*) -- Anything to be saved in the training "
"queue together with the architecture. * **generated_graph** (*Graph*) -- "
"An instance of Graph."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate:3
#: of
msgid ""
"**other_info** (*any object*) -- Anything to be saved in the training "
"queue together with the architecture."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate:4
#: of
msgid "**generated_graph** (*Graph*) -- An instance of Graph."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.generate_parameters:1
#: of
msgid "Returns a set of trial neural architecture, as a serializable object."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_best_model_id:1
#: of
msgid "Get the best model_id from history using the metric value"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id:1
#: of
msgid "Get the model metric valud by its model_id"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id:3
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id:3
#: of
msgid "model index"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.get_metric_value_by_id:6
#: of
msgid "the model metric"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.init_search:1
#: of
msgid "Call the generators to generate the initial architectures for the search."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_best_model:1
#: of
msgid "Get the best model by model id"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_best_model:3
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id:6
#: of
msgid "**load_model** -- the model graph representation"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.load_model_by_id:1
#: of
msgid "Get the model by model_id"
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.receive_trial_result:1
#: of
msgid "Record an observation of the objective function."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.receive_trial_result:3
#: of
msgid "the id of a group of paramters that generated by nni manager."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.receive_trial_result:5
#: of
msgid "A group of parameters."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.receive_trial_result:7
#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.receive_trial_result:7
#: of
msgid "if value is dict, it should have \"default\" key."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update:1
#: of
msgid "Update the controller with evaluation result of a neural architecture."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update:3
#: of
msgid "In our case it is the father ID in the search tree."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update:5
#: of
msgid "An instance of Graph. The trained neural architecture."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update:7
#: of
msgid "The final evaluated metric value."
msgstr ""

#: nni.algorithms.hpo.networkmorphism_tuner.networkmorphism_tuner.NetworkMorphismTuner.update_search_space:1
#: of
msgid ""
"Update search space definition in tuner by search_space in neural "
"architecture."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:1 of
msgid "Metis Tuner"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:3 of
msgid ""
"More algorithm information you could reference here: "
"https://www.microsoft.com/en-us/research/publication/metis-robustly-"
"tuning-tail-latencies-cloud-systems/"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:8 of
msgid ""
"optimize_mode is a string that including two mode \"maximize\" and "
"\"minimize\""
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:14 of
msgid ""
"True or False. Should Metis consider re-sampling as part of the search "
"strategy? If you are confident that the training dataset is noise-free, "
"then you do not need re-sampling."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:23 of
msgid ""
"True or False. Should Metis suggest parameters for the next benchmark? If"
" you do not plan to do more benchmarks, Metis can skip this step."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:32 of
msgid ""
"How many times Metis should try to find the global optimal in the search "
"space? The higher the number, the longer it takes to output the solution."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:39 of
msgid ""
"Metis need some trial result to get cold start. when the number of trial "
"result is less than cold_start_num, Metis will randomly sample hyper-"
"parameter for trial."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner:47 of
msgid ""
"The probability of Metis to select parameter from exploration instead of "
"exploitation."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters:1
#: of
msgid "Generate next parameter for trial"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters:3
#: of
msgid ""
"If the number of trial result is lower than cold start number, metis will"
" first random generate some parameters. Otherwise, metis will choose the "
"parameters by the Gussian Process Model and the Gussian Mixture Model."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.generate_parameters:11
#: of
msgid "**result**"
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.import_data:3 of
msgid "each of which has at least two keys: 'parameter' and 'value'."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.receive_trial_result:1
#: of
msgid "Tuner receive result from trial."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.receive_trial_result:3
#: of
msgid "The id of parameters, generated by nni manager."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.receive_trial_result:5
#: of
msgid "A group of parameters that trial has tried."
msgstr ""

#: nni.algorithms.hpo.metis_tuner.metis_tuner.MetisTuner.update_search_space:1
#: of
msgid "Update the self.x_bounds and self.x_types by the search_space.json"
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner:1 of
msgid ""
"PPOTuner, the implementation inherits the main logic of the "
"implementation [ppo2 from "
"openai](https://github.com/openai/baselines/tree/master/baselines/ppo2), "
"and is adapted for NAS scenario. It uses ``lstm`` for its policy network "
"and value network, policy and value share the same network."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_multiple_parameters:1
#: of
msgid ""
"Returns multiple sets of trial (hyper-)parameters, as iterable of "
"serializable objects."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.generate_parameters:1 of
msgid ""
"Generate parameters, if no trial configration for now, self.credit plus 1"
" to send the config later"
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.import_data:1 of
msgid "Import additional data for tuning, not supported yet."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.import_data:3 of
msgid ""
"A list of dictionarys, each of which has at least two keys, ``parameter``"
" and ``value``"
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.receive_trial_result:1 of
msgid ""
"Receive trial's result. if the number of finished trials equals "
"self.inf_batch_size, start the next update to train the model."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.trial_end:1 of
msgid ""
"To deal with trial failure. If a trial fails, it is popped out from "
"``self.running_trials``, and the final result of this trial is assigned "
"with the average of the finished trials."
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.update_search_space:1 of
msgid "Get search space, currently the space only includes that for NAS"
msgstr ""

#: nni.algorithms.hpo.ppo_tuner.ppo_tuner.PPOTuner.update_search_space:3 of
msgid ""
"Search space for NAS the format could be referred to search space spec "
"(https://nni.readthedocs.io/en/latest/Tutorial/SearchSpaceSpec.html)."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner:1 of
msgid ""
"BatchTuner is tuner will running all the configure that user want to run "
"batchly."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner:4 of
msgid "Examples"
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner:5 of
msgid "The search space only be accepted like:"
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.generate_parameters:1 of
msgid "Returns a dict of trial (hyper-)parameters, as a serializable object."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.generate_parameters:6 of
msgid "A candidate parameter group."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.is_valid:1 of
msgid "Check the search space is valid: only contains 'choice' type"
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.is_valid:6 of
msgid "If valid, return candidate values; else return None."
msgstr ""

#: nni.algorithms.hpo.batch_tuner.BatchTuner.update_search_space:1 of
msgid "Update the search space"
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:1 of
msgid ""
"GPTuner is a Bayesian Optimization method where Gaussian Process is used "
"for modeling loss functions."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:3 of
msgid "optimize mode, 'maximize' or 'minimize', by default 'maximize'"
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:5 of
msgid ""
"utility function (also called 'acquisition funcition') to use, which can "
"be 'ei', 'ucb' or 'poi'. By default 'ei'."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:7 of
msgid ""
"value used by utility function 'ucb'. The bigger kappa is, the more the "
"tuner will be exploratory. By default 5."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:9 of
msgid ""
"used by utility function 'ei' and 'poi'. The bigger xi is, the more the "
"tuner will be exploratory. By default 0."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:11 of
msgid ""
"used to specify Matern kernel. The smaller nu, the less smooth the "
"approximated function is. By default 2.5."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:13 of
msgid ""
"Used to specify Gaussian Process Regressor. Larger values correspond to "
"increased noise level in the observations. By default 1e-6."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:16 of
msgid ""
"Number of random exploration to perform before Gaussian Process. By "
"default 10."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:18 of
msgid ""
"Number of random points to evaluate for getting the point which maximizes"
" the acquisition function. By default 100000"
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner:20 of
msgid ""
"Number of times to run L-BFGS-B from a random starting point after the "
"warmup. By default 250."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.generate_parameters:1 of
msgid ""
"Method which provides one set of hyper-parameters. If the number of trial"
" result is lower than cold_start_number, GPTuner will first randomly "
"generate some parameters. Otherwise, choose the parameters by the Gussian"
" Process Model."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.generate_parameters:5
#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.import_data:3
#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.receive_trial_result:3
#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.update_search_space:3 of
msgid "Override of the abstract method in :class:`~nni.tuner.Tuner`."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.receive_trial_result:1 of
msgid "Method invoked when a trial reports its final result."
msgstr ""

#: nni.algorithms.hpo.gp_tuner.gp_tuner.GPTuner.update_search_space:1 of
msgid "Update the self.bounds and self.types by the search_space.json file."
msgstr ""

#: ../../autotune_ref.rst:57
msgid "Assessor"
msgstr ""

#: nni.assessor.Assessor:1 of
msgid ""
"Assessor analyzes trial's intermediate results (e.g., periodically "
"evaluated accuracy on test dataset) to tell whether this trial can be "
"early stopped or not."
msgstr ""

#: nni.assessor.Assessor:4 of
msgid ""
"This is the abstract base class for all assessors. Early stopping "
"algorithms should inherit this class and override :meth:`assess_trial` "
"method, which receives intermediate results from trials and give an "
"assessing result."
msgstr ""

#: nni.assessor.Assessor:8 of
msgid ""
"If :meth:`assess_trial` returns :obj:`AssessResult.Bad` for a trial, it "
"hints NNI framework that the trial is likely to result in a poor final "
"accuracy, and therefore should be killed to save resource."
msgstr ""

#: nni.assessor.Assessor:12 of
msgid ""
"If an assessor want's to be notified when a trial ends, it can also "
"override :meth:`trial_end`."
msgstr ""

#: nni.assessor.Assessor:14 of
msgid ""
"To write a new assessor, you can reference "
":class:`~nni.medianstop_assessor.MedianstopAssessor`'s code as an "
"example."
msgstr ""

#: nni.assessor.Assessor:16 of
msgid ""
":obj:`Builtin`, "
":class:`~nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor`, "
":class:`~nni.algorithms.hpo.curvefitting_assessor.CurvefittingAssessor`"
msgstr ""

#: nni.assessor.Assessor.assess_trial:1 of
msgid ""
"Abstract method for determining whether a trial should be killed. Must "
"override."
msgstr ""

#: nni.assessor.Assessor.assess_trial:3 of
msgid ""
"The NNI framework has little guarantee on ``trial_history``. This method "
"is not guaranteed to be invoked for each time ``trial_history`` get "
"updated. It is also possible that a trial's history keeps updating after "
"receiving a bad result. And if the trial failed and retried, "
"``trial_history`` may be inconsistent with its previous value."
msgstr ""

#: nni.assessor.Assessor.assess_trial:8 of
msgid ""
"The only guarantee is that ``trial_history`` is always growing. It will "
"not be empty and will always be longer than previous value."
msgstr ""

#: nni.assessor.Assessor.assess_trial:11 of
msgid "This is an example of how :meth:`assess_trial` get invoked sequentially:"
msgstr ""

#: nni.assessor.Assessor.assess_trial:22 nni.assessor.Assessor.trial_end:3 of
msgid "Unique identifier of the trial."
msgstr ""

#: nni.assessor.Assessor.assess_trial:24 of
msgid ""
"Intermediate results of this trial. The element type is decided by trial "
"code."
msgstr ""

#: nni.assessor.Assessor.assess_trial:27 of
msgid ":obj:`AssessResult.Good` or :obj:`AssessResult.Bad`."
msgstr ""

#: nni.assessor.AssessResult:1 of
msgid "Enum class for :meth:`Assessor.assess_trial` return value."
msgstr ""

#: ../../docstring nni.assessor.AssessResult.Bad:1 of
msgid "The trial works poorly and should be early stopped."
msgstr ""

#: ../../docstring nni.assessor.AssessResult.Good:1 of
msgid "The trial works well."
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor:1
#: of
msgid ""
"CurvefittingAssessor uses learning curve fitting algorithm to predict the"
" learning curve performance in the future. It stops a pending trial X at "
"step S if the trial's forecast result at target step is convergence and "
"lower than the best performance in the history."
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor:5
#: of
msgid "The total number of epoch"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor:7
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor:7 of
msgid "only after receiving start_step number of reported intermediate results"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor:9
#: of
msgid "The threshold that we decide to early stop the worse performance curve."
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial:1
#: of
msgid "assess whether a trial should be early stop by curve fitting algorithm"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial:3
#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.trial_end:3
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial:1
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.trial_end:1 of
msgid "trial job id"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial:5
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial:3 of
msgid "The history performance matrix of each trial"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial:8
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial:6 of
msgid "AssessResult.Good or AssessResult.Bad"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.assess_trial:11
#: of
msgid "unrecognize exception in curvefitting_assessor"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.trial_end:1
#: of
msgid "update the best performance of completed trial job"
msgstr ""

#: nni.algorithms.hpo.curvefitting_assessor.curvefitting_assessor.CurvefittingAssessor.trial_end:5
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.trial_end:3 of
msgid "True if succssfully finish the experiment, False otherwise"
msgstr ""

#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor:1 of
msgid ""
"MedianstopAssessor is The median stopping rule stops a pending trial X at"
" step S if the trial’s best objective value by step S is strictly worse "
"than the median value of the running averages of all completed trials’ "
"objectives reported up to step S"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:7
#: nni.algorithms.hpo.hyperband_advisor.Hyperband:10
#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor:5 of
msgid "optimize mode, 'maximize' or 'minimize'"
msgstr ""

#: nni.algorithms.hpo.medianstop_assessor.MedianstopAssessor.assess_trial:9 of
msgid "unrecognize exception in medianstop_assessor"
msgstr ""

#: ../../autotune_ref.rst:72
msgid "Advisor"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase:1 of
msgid ""
"This is where tuners and assessors are not defined yet. Inherits this "
"class to make your own advisor."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.command_queue_worker:1 of
msgid "Process commands in command queues."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.enqueue_command:1 of
msgid "Enqueue command into command queues"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_add_customized_trial:1
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_add_customized_trial:1
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_add_customized_trial:1
#: of
msgid "Experimental API. Not recommended for usage."
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_import_data:1
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_import_data:1 of
msgid ""
"Import previous data when experiment is resumed. :param data: a list of "
"dictionaries, each of which has at least two keys, 'parameter' and "
"'value' :type data: list"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_initialize:1 of
msgid ""
"Initialize search space and tuner, if any This method is meant to be "
"called only once for each experiment, after calling this method, "
"dispatcher should `send(CommandType.Initialized, '')`, to set the status "
"of the experiment to be \"INITIALIZED\". :param data: search space :type "
"data: dict"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_report_metric_data:1
#: of
msgid ""
"Called when metric data is reported or new parameters are requested (for "
"multiphase). When new parameters are requested, this method should send a"
" new parameter."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_report_metric_data:4
#: of
msgid ""
"a dict which contains 'parameter_id', 'value', 'trial_job_id', 'type', "
"'sequence'. type: can be `MetricType.REQUEST_PARAMETER`, "
"`MetricType.FINAL` or `MetricType.PERIODICAL`. `REQUEST_PARAMETER` is "
"used to request new parameters for multiphase trial job. In this case, "
"the dict will contain additional keys: `trial_job_id`, `parameter_index`."
" Refer to `msg_dispatcher.py` as an example."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_report_metric_data:11
#: of
msgid "Data type is not supported"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_request_trial_jobs:1
#: of
msgid ""
"The message dispatcher is demanded to generate ``data`` trial jobs. These"
" trial jobs should be sent via ``send(CommandType.NewTrialJob, "
"nni.dump(parameter))``, where ``parameter`` will be received by NNI "
"Manager and eventually accessible to trial jobs as \"next parameter\". "
"Semantically, message dispatcher should do this ``send`` exactly ``data``"
" times."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_request_trial_jobs:6
#: of
msgid "The JSON sent by this method should follow the format of"
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_request_trial_jobs:1
#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_request_trial_jobs:18
#: of
msgid "number of trial jobs"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_trial_end:1 of
msgid "Called when the state of one of the trials is changed"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_trial_end:3 of
msgid ""
"a dict with keys: trial_job_id, event, hyper_params. trial_job_id: the id"
" generated by training service. event: the job’s state. hyper_params: the"
" string that is sent by message dispatcher during the creation of trials."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.handle_update_search_space:1
#: of
msgid ""
"This method will be called when search space is updated. It's recommended"
" to call this method in `handle_initialize` to initialize search space. "
"*No need to* notify NNI Manager when this update is done. :param data: "
"search space :type data: dict"
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.process_command_thread:1
#: of
msgid "Worker thread to process a command."
msgstr ""

#: nni.runtime.msg_dispatcher_base.MsgDispatcherBase.run:1 of
msgid "Run the tuner. This function will never return unless raise."
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband:1 of
msgid ""
"Hyperband inherit from MsgDispatcherBase rather than Tuner, because it "
"integrates both tuner's functions and assessor's functions. This is an "
"implementation that could fully leverage available resources or follow "
"the algorithm process, i.e., high parallelism or serial. A single "
"execution of Hyperband takes a finite budget of (s_max + 1)B."
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband:6 of
msgid ""
"the maximum amount of resource that can be allocated to a single "
"configuration"
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband:8 of
msgid ""
"the variable that controls the proportion of configurations discarded in "
"each round of SuccessiveHalving"
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband:12 of
msgid "execution mode, 'serial' or 'parallelism'"
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_initialize:1 of
msgid ""
"callback for initializing the advisor :param data: search space :type "
"data: dict"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_report_metric_data:3
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_report_metric_data:1
#: of
msgid ""
"it is an object which has keys 'parameter_id', 'value', 'trial_job_id', "
"'type', 'sequence'."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_report_metric_data:5
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_report_metric_data:3
#: of
msgid "Data type not supported"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_trial_end:3
#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_trial_end:1 of
msgid ""
"it has three keys: trial_job_id, event, hyper_params trial_job_id: the id"
" generated by training service event: the job's state hyper_params: the "
"hyperparameters (a string) generated and returned by tuner"
msgstr ""

#: nni.algorithms.hpo.hyperband_advisor.Hyperband.handle_update_search_space:1
#: of
msgid "data: JSON object, which is search space"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:1 of
msgid ""
"BOHB performs robust and efficient hyperparameter optimization at scale "
"by combining the speed of Hyperband searches with the guidance and "
"guarantees of convergence of Bayesian Optimization. Instead of sampling "
"new configurations at random, BOHB uses kernel density estimators to "
"select promising candidates."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:9 of
msgid "The smallest budget to consider. Needs to be positive!"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:11 of
msgid ""
"The largest budget to consider. Needs to be larger than min_budget! The "
"budgets will be geometrically distributed :math:`a^2 + b^2 = c^2 \\sim "
"\\eta^k` for :math:`k\\in [0, 1, ... , num\\_subsets - 1]`."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:15 of
msgid ""
"In each iteration, a complete run of sequential halving is executed. In "
"it, after evaluating each configuration on the same subset size, only a "
"fraction of 1/eta of them 'advances' to the next round. Must be greater "
"or equal to 2."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:20 of
msgid ""
"number of observations to start building a KDE. Default 'None' means "
"dim+1, the bare minimum."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:23 of
msgid ""
"percentage ( between 1 and 99, default 15) of the observations that are "
"considered good."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:25 of
msgid "number of samples to optimize EI (default 64)"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:29 of
msgid "prior without the model."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:30 of
msgid ""
"to encourage diversity, the points proposed to optimize EI, are sampled "
"from a 'widened' KDE where the bandwidth is multiplied by this factor "
"(default: 3)"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB:33 of
msgid ""
"to keep diversity, even when all (good) samples have the same value for "
"one of the parameters, a minimum bandwidth (Default: 1e-3) is used "
"instead of zero."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.generate_new_bracket:1 of
msgid "generate a new bracket"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_import_data:5 of
msgid "data doesn't have required key 'parameter' and 'value'"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_initialize:1 of
msgid ""
"Initialize Tuner, including creating Bayesian optimization-based "
"parametric models and search space formations"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_initialize:4
#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_update_search_space:3
#: of
msgid "search space of this experiment"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_initialize:7 of
msgid "Error: Search space is None"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_report_metric_data:1
#: of
msgid "reveice the metric data and update Bayesian optimization with final result"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_request_trial_jobs:1
#: of
msgid "recerive the number of request and generate trials"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_request_trial_jobs:3
#: of
msgid "number of trial jobs that nni manager ask to generate"
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_trial_end:1 of
msgid "receive the information of trial end and generate next configuaration."
msgstr ""

#: nni.algorithms.hpo.bohb_advisor.bohb_advisor.BOHB.handle_update_search_space:1
#: of
msgid "change json format to ConfigSpace format dict<dict> -> configspace"
msgstr ""

#: ../../autotune_ref.rst:84
msgid "Utilities"
msgstr ""

#: nni.utils.merge_parameter:1 of
msgid ""
"Update the parameters in ``base_params`` with ``override_params``. Can be"
" useful to override parsed command line arguments."
msgstr ""

#: nni.utils.merge_parameter:4 of
msgid "Base parameters. A key-value mapping."
msgstr ""

#: nni.utils.merge_parameter:6 of
msgid ""
"Parameters to override. Usually the parameters got from "
"``get_next_parameters()``. When it is none, nothing will happen."
msgstr ""

#: nni.utils.merge_parameter:10 of
msgid ""
"The updated ``base_params``. Note that ``base_params`` will be updated "
"inplace. The return value is only for convenience."
msgstr ""

#: nni.common.serializer.trace:1 of
msgid ""
"Annotate a function or a class if you want to preserve where it comes "
"from. This is usually used in the following scenarios:"
msgstr ""

#: nni.common.serializer.trace:4 of
msgid ""
"Care more about execution configuration rather than results, which is "
"usually the case in AutoML. For example, you want to mutate the "
"parameters of a function."
msgstr ""

#: nni.common.serializer.trace:6 of
msgid ""
"Repeat execution is not an issue (e.g., reproducible, execution is fast "
"without side effects)."
msgstr ""

#: nni.common.serializer.trace:8 of
msgid ""
"When a class/function is annotated, all the instances/calls will return a"
" object as it normally will. Although the object might act like a normal "
"object, it's actually a different object with NNI-specific properties. "
"One exception is that if your function returns None, it will return an "
"empty traceable object instead, which should raise your attention when "
"you want to check whether the None ``is None``."
msgstr ""

#: nni.common.serializer.trace:13 of
msgid ""
"When parameters of functions are received, it is first stored, and then a"
" shallow copy will be passed to wrapped function/class. This is to "
"prevent mutable objects gets modified in the wrapped function/class. When"
" the function finished execution, we also record extra information about "
"where this object comes from. That's why it's called \"trace\". When call"
" ``nni.dump``, that information will be used, by default."
msgstr ""

#: nni.common.serializer.trace:19 of
msgid ""
"If ``kw_only`` is true, try to convert all parameters into kwargs type. "
"This is done by inspecting the argument list and types. This can be "
"useful to extract semantics, but can be tricky in some corner cases. "
"Therefore, in some cases, some positional arguments will still be kept."
msgstr ""

#: nni.common.serializer.trace:25 of
msgid ""
"Generators will be first expanded into a list, and the resulting list "
"will be further passed into the wrapped function/class. This might hang "
"when generators produce an infinite sequence. We might introduce an API "
"to control this behavior in future."
msgstr ""

#: nni.common.serializer.trace:28 of
msgid "Example:"
msgstr ""

#: nni.common.serializer.dump:1 of
msgid ""
"Convert a nested data structure to a json string. Save to file if fp is "
"specified. Use json-tricks as main backend. For unhandled cases in json-"
"tricks, use cloudpickle. The serializer is not designed for long-term "
"storage use, but rather to copy data between processes. The format is "
"also subject to change between NNI releases."
msgstr ""

#: nni.common.serializer.dump:6 of
msgid "The object to dump."
msgstr ""

#: nni.common.serializer.dump:8 of
msgid "File to write to. Keep it none if you want to dump a string."
msgstr ""

#: nni.common.serializer.dump:10 of
msgid ""
"This is set to avoid too long serialization result. Set to -1 to disable "
"size check."
msgstr ""

#: nni.common.serializer.dump:12 of
msgid ""
"Whether to allow nan to be serialized. Different from default value in "
"json-tricks, our default value is true."
msgstr ""

#: nni.common.serializer.dump:14 of
msgid "Other keyword arguments passed to json tricks (backend), e.g., indent=2."
msgstr ""

#: nni.common.serializer.dump:17 of
msgid "Normally str. Sometimes bytes (if compressed)."
msgstr ""

#: nni.common.serializer.load:1 of
msgid ""
"Load the string or from file, and convert it to a complex data structure."
" At least one of string or fp has to be not none."
msgstr ""

#: nni.common.serializer.load:4 of
msgid "JSON string to parse. Can be set to none if fp is used."
msgstr ""

#: nni.common.serializer.load:6 of
msgid "File path to load JSON from. Can be set to none if string is used."
msgstr ""

#: nni.common.serializer.load:8 of
msgid "Remove comments (starting with ``#`` or ``//``). Default is true."
msgstr ""

#: nni.common.serializer.load:11 of
msgid "The loaded object."
msgstr ""

